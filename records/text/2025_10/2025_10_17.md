1. Kernel Trick (in SVM)
   1. 分类/回归 (Supervised)：在高维空间中找到一个线性决策边界，从而解决原始空间中的非线性问题。
   2. 升维 (Implicit)：X (低维) -> F (高维)。Φ(x)将数据映射到更高维空间。
   3. 隐式 (Implicit)：我们从不真正计算高维向量Φ(x)。只通过核函数K(x, z) = <Φ(x), Φ(z)>来计算它们在高维空间中的内积。这是“Trick”的关键。
2. 流形学习 (Manifold Learning)
   1. 降维/数据可视化 (Unsupervised)：发现并“展开”嵌入在高维数据中的低维流形结构，以更少的维度来表示数据。
   2. 降维 (Explicit)：X (高维) -> Y (低维)。找到一个映射f: X -> Y，其中dim(Y) < dim(X)。
   3. 显式 (Explicit)：通常会显式地计算出数据在低维空间中的坐标。例如，t-SNE或Isomap算法会直接输出每个数据点的二维或三维坐标。