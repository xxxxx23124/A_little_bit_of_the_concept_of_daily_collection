1. 看蛊真人有感，如果从词向量的角度简单定义坚持，坚持 = (目标 + 困境) - (绝望 + 怀疑) + (行动 + 无畏)。这应该可以作为一个近似。
   - 如果我们把整个字典的词汇都编码为词向量，那么是不是说明这个字典是低秩的，而且非常低秩。就比如我们可以通过其他词汇线性地构造出这个“坚持”的概念？
     - 我们先理解“秩”（Rank）在矩阵中的含义。一个矩阵的秩，可以通俗地理解为构成这个矩阵所有信息的“独立基本维度”的数量。
     - 如果一个矩阵是“低秩”的，意味着它的大部分行（或列）都可以由少数几个“基本行/列”线性组合而成，其中包含了大量的冗余信息。
     - 现在，我们把整个字典看作一个巨大的“词-特征”矩阵 M。每一行代表一个词（比如“女皇”、“国王”），每一列代表一个语义特征（比如“性别”、“权力”、“年龄”等，虽然在实际模型中这些特征是隐性的，但我们可以这样理解）。
     - 国王 的向量可以看作是 [权力_高, 性别_男, 年龄_成年, ...]
     - 男人 的向量可以看作是 [权力_低, 性别_男, 年龄_成年, ...]
     - 女人 的向量可以看作是 [权力_低, 性别_女, 年龄_成年, ...]
     - 女皇 的向量可以看作是 [权力_高, 性别_女, 年龄_成年, ...]
     - 国王 - 男人 这个操作，在向量空间里近似于抵消了共有的 [性别_男, 年龄_成年] 等特征，保留了 [权力_高] 这个核心差异。
     - 然后 + 女人，相当于把 [权力_高] 这个“权力”特征嫁接到 女人 的基础上。
     - 这个简单的加减法之所以能成立，恰恰说明了词与词之间的关系不是完全独立的。它们共享着某些底层的、数量远少于词汇总数的“语义组件”（如性别、权力、动作、情感等）。这些语义组件就是我们上面说的“基本维度”。
     - 如果字典是“满秩”的，那么每个词都是一个完全独立的、无法被其他词表示的基本概念。那样的话，国王 - 男人 + 女人 的结果将是一个毫无意义的、混乱的向量，绝不可能指向“女皇”。

2. 有没有科学家研究，比如中文这门语言，大概日常生活用语的RANK是多少？
   - 答案是：有，但并非直接计算一个叫做“语言秩”（Language Rank）的单一数字。 科学家们通过多种方式来研究和量化语言的“有效维度”或“内在维度”（Intrinsic Dimension），这在概念上与你所说的“秩”高度相关。
   1. 定义边界不清： “日常生活用语”的边界是模糊的。是3000个高频词？还是包括网络用语的10000个词？选择不同的词汇集合，得到的“词汇矩阵”就不同，其秩也自然不同。
   2. “特征”是隐性的： 在理想的数学模型中，我们可以假设“国王”有“权力”、“性别”等清晰的特征。但在真实的词向量中，那几百个维度并没有明确的标签。它们是模型在海量数据中统计学习到的抽象语义组合。因此，我们无法像数矩阵的独立行/列那样直接数出“秩”。
   3. 非线性关系： 词与词之间的关系不完全是线性的。虽然 国王 - 男人 + 女人 ≈ 女皇 这样的线性类比很惊艳，但它只是一个近似。语言中还存在大量复杂的非线性关系（如比喻、反讽、一词多义），这使得简单的线性代数工具（如秩）无法完全捕捉其复杂性。
   -  研究方法：
     - 主成分分析 (PCA, Principal Component Analysis)
     - 非线性降维方法 (Manifold Learning)
     - 分形维度 (Fractal Dimension) 估算
   - 相关研究与发现（以英文研究为例，中文情况类似）：
     - 一篇2018年发表在ICLR（顶级AI会议）的论文《On the Intrinsic Dimensionality of Word Representations》使用 TwoNN 算法发现，对于包含数万词汇的英文GloVe词向量（原始维度300），其内在维度大约只有10到20之间！

3. 有一个反直觉的现象叫做“过参数化”（Over-parameterization）的好处。更大的模型（更多的参数）虽然理论上更难优化，但其损失函数的“地形”实际上可能更平滑，有更多的路径可以走向一个“足够好”的解。相比之下，一个紧凑的小模型，其损失函数的地形可能非常崎岖，优化算法很容易陷入一个糟糕的局部最优而无法自拔。增大d_model可以看作是为优化过程提供了更多的“冗余”和“缓冲”，让模型更容易被训练好。

4. 词向量应该解耦（Disentangled）还是纠缠（Entangled）？

5. 食辐射真菌 / “耐辐射奇球菌”（Deinococcus radiodurans）