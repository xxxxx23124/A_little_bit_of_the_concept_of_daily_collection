1. 对Embedding层使用Dropout: 对token_embedding使用embedding_dropout的核心目的是：防止模型过度依赖于某些特定的词或词的组合（co-adaptation），从而提高模型的泛化能力。
    1. 在一个标准的训练过程中：
       * 一个词（比如 "amazing"）总是被映射到完全相同的嵌入向量（embedding vector）。
       * 模型在成千上万次的迭代中，会学会利用这个固定的 "amazing" 向量来预测正面情感。
       * 更进一步，模型可能会学到非常具体的词共现模式（co-occurrence patterns）。例如，它可能会学到只要 "not" 和 "amazing" 的向量同时出现，就代表负面情感；而只要 "very" 和 "amazing" 的向量同时出现，就代表非常正面的情感。
      这种学习方式本身没有错，但它存在一个风险：过度拟合（Overfitting）。
      模型可能会变得“脆弱”，它过于依赖这些在训练集中常见的、特定的词向量组合。如果测试集中出现了一个稍微不同的表达方式，比如用 "incredible" 替代 "amazing"，或者用 "isn't" 替代 "not"，模型可能就无法很好地泛化，因为它没有学到更抽象的“否定”或“强调”的概念，而只是记住了特定向量之间的交互。
    2. nn.Dropout 的工作原理是：在训练期间，以一定的概率 p，将输入张量中的某些元素随机地置为零。为了保持整体的期望值不变，剩余的非零元素会被放大 1 / (1 - p) 倍。
      当我们将Dropout应用在Embedding层之后：
       * 输入： 假设我们有一个batch的句子，经过token_embedding后，得到一个形状为 (batch_size, seq_len, d_model) 的嵌入矩阵。
       * embedding_dropout 操作： nn.Dropout会作用于这个矩阵。重要的是，标准的nn.Dropout是独立地对每个元素（每个浮点数）进行操作的。
       * 效果： 这意味着一个词（比如 "amazing"）的嵌入向量，在每次前向传播时，都会变得不完全一样。它的768个维度中，有一部分会被随机置为零，而另一部分会被放大。
      这就像在每次看到 "amazing" 这个词时，模型都被迫戴上了一副“部分失明”的眼镜。这次它可能看不到这个词向量中与“情感强度”相关的维度，下次可能看不到与“口语化”相关的维度。
    3. 不要过度依赖单个词： 因为任何一个词的嵌入向量都可能在某次迭代中变得“不完整”，模型不能只依赖 "amazing" 这一个词来做判断。它必须学会综合考虑句子中的其他词，比如 "The movie was ... truly ... masterpiece."，即使 "amazing" 的信息不完整，也能根据上下文做出正确的判断。
    
    4. 不要过度依赖词的特定组合： 模型不能再死记硬背“not的向量 + amazing的向量 = 负面”。因为这两个向量每次都是“残缺不全”的，模型必须学习一种更泛化的方式来理解“否定”这个概念是如何作用于“正面词汇”的。它被迫去学习一个更抽象的交互模式，而不是特定向量数值上的加加减减。
    
    5. 促进嵌入向量内部维度的信息冗余： 这有点像RAID磁盘阵列。因为任何一个维度都可能随时“下线”，模型被鼓励将同一个概念（比如“正面情感”）的信息分布在嵌入向量的多个维度上。这样，即使部分维度被dropout，其他维度仍然可以提供足够的信息。这使得学习到的嵌入向量本身也更加健壮。
    6. 特殊的Dropout：Word Dropout vs Standard Dropout
2. Kronecker积分解